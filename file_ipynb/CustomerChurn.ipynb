{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import pydot\n",
    "import pydotplus\n",
    "from sklearn.externals.six import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_cust = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_cust.TotalCharges = pd.to_numeric(telecom_cust.TotalCharges, errors='coerce')\n",
    "telecom_cust.MonthlyCharges = pd.to_numeric(telecom_cust.MonthlyCharges, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Removing the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_missing_values(telecom_cust):\n",
    "    telecom_cust.dropna(inplace = True);\n",
    "    telecom_cust.reset_index(drop=True, inplace = True);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n",
      "(7032, 21)\n"
     ]
    }
   ],
   "source": [
    "print(telecom_cust.shape);\n",
    "removing_missing_values(telecom_cust);\n",
    "print(telecom_cust.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_cust.to_csv(\"WA_Fn-UseC_-Telco-Customer-Churn-standard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Removing the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_duplicates(telecom_cust):\n",
    "    telecom_cust = pd.DataFrame.drop_duplicates(telecom_cust);\n",
    "    telecom_cust.reset_index(drop=True, inplace = True);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7032, 21)\n"
     ]
    }
   ],
   "source": [
    "removing_duplicates(telecom_cust);\n",
    "print(telecom_cust.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Using mean-method in handling the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the missing values by mean-method.\n",
    "def set_missing_values_by_MEAN_METHOD(telecom_cust):\n",
    "    list_name_of_attributes = telecom_cust.columns;\n",
    "    for i in list_name_of_attributes:\n",
    "        #print(telecom_cust[i].value_counts().index);\n",
    "        if(telecom_cust[i].isnull().sum()>0 and telecom_cust[i].dtypes != 'object'):\n",
    "            telecom_cust[i].fillna(telecom_cust[i].mean(), inplace=True);\n",
    "        else:\n",
    "            if (telecom_cust[i].isnull().sum()>0 and telecom_cust[i].dtypes == 'object'):\n",
    "                #print(telecom_cust[i].value_counts().index);\n",
    "                telecom_cust[i].fillna(telecom_cust[i].value_counts().index.sort_values()[0], inplace=True);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_missing_values_by_MEAN_METHOD(telecom_cust);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Using mode-method in handling the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the missing values by mode-method.\n",
    "def set_missing_values_by_MODE_METHOD(telecom_cust):\n",
    "    list_name_of_attributes = telecom_cust.columns;\n",
    "    for i in list_name_of_attributes:\n",
    "        if(telecom_cust[i].isnull().sum()>0 and telecom_cust[i].dtypes != 'object'):\n",
    "            telecom_cust[i].fillna(telecom_cust[i].mode()[0], inplace=True);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_missing_values_by_MODE_METHOD(telecom_cust);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Using median-method in handling the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the missing values by median-method.\n",
    "def set_missing_values_by_MEDIAN_METHOD(telecom_cust):\n",
    "    list_name_of_attributes = telecom_cust.columns;\n",
    "    for i in list_name_of_attributes:\n",
    "        if(telecom_cust[i].isnull().sum()>0):\n",
    "            telecom_cust[i].fillna(telecom_cust[i].median(), inplace=True);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_missing_values_by_MEDIAN_METHOD(telecom_cust);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Normalizing data by max-min method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max-min method\n",
    "def normalization_data_max_min(telecom_cust):\n",
    "    for i in telecom_cust.columns:\n",
    "        if telecom_cust[i].dtypes != 'object':\n",
    "            max_value = telecom_cust[i].max();\n",
    "            min_value = telecom_cust[i].min();\n",
    "            telecom_cust[i] = (telecom_cust[i] - min_value)/(max_value - min_value);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_data_max_min(telecom_cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Normalizing data by z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-score method\n",
    "def normalization_data_z_score(telecom_cust):\n",
    "    for i in telecom_cust.columns:\n",
    "        if telecom_cust[i].dtypes != 'object':\n",
    "            meanX = telecom_cust[i].mean();\n",
    "            sd = telecom_cust[i].std();\n",
    "            telecom_cust[i] = (telecom_cust[i]-meanX)/sd;\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_data_z_score(telecom_cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Outlier detection by zscores for all rows with one method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(telecom_cust[\"TotalCharges\"]);\n",
    "def outlier_detection_by_zscores(telecom_cust, start, end):\n",
    "    print(\"Condition: Data frame must be normalized by z-scores before\");\n",
    "    for i in telecom_cust.columns:\n",
    "        if telecom_cust[i].dtypes != 'object':\n",
    "            telecom_cust[\"outlier\"] = telecom_cust[i].apply(lambda x: x <=start or x >= end);\n",
    "            outlier_indx = telecom_cust[telecom_cust.outlier==True].index.values;\n",
    "            if (len(outlier_indx)>0):\n",
    "                telecom_cust.iloc[outlier_indx,:]=np.nan;\n",
    "            telecom_cust.drop(\"outlier\", axis=1, inplace=True);\n",
    "    removing_missing_values(telecom_cust);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detection_by_zscores(telecom_cust,-2.5, 2.5)\n",
    "print(telecom_cust.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Remove a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove customer IDs from the data set\n",
    "df2 = telecom_cust.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Converting the string to int in the classed var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertin the predictor variable in a binary numeric variable\n",
    "df2['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "df2['Churn'].replace(to_replace='No',  value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Convert all off categorical variables into dummy var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7032, 46)\n"
     ]
    }
   ],
   "source": [
    "#Let's convert all the categorical variables into dummy variables\n",
    "df_dummies = pd.get_dummies(df2);\n",
    "print(df_dummies.shape)\n",
    "df_dummies_dbscan = pd.get_dummies(df2);\n",
    "#label = df_dummies['Churn'].copy();\n",
    "#df_dummies.drop(\"Churn\", axis=1, inplace = True);\n",
    "#df_dummies['Churn']=label;\n",
    "#df_dummies.to_csv(\"CustomerChurn.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Data Discretisation by Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_discretisation_by_decision_tree(df, col_1_name, col_2_name, Test_size = 0.3, Max_depth = 3):\n",
    "    tree_model = DecisionTreeClassifier(max_depth = Max_depth);\n",
    "    #print(tree_model);\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df[col_1_name], df[col_2_name], test_size = Test_size);\n",
    "    #print(X_train['TotalCharges'].dtypes);\n",
    "    #print(Y_train['Churn'].dtypes);\n",
    "    tree_model.fit(X_train.to_frame(), Y_train.to_frame());\n",
    "    #print(\"X train shape = (%d , %d)\"%X_train.shape + \", Y train shape = (%d , %d)\"%Y_train.shape);\n",
    "    label = tree_model.predict_proba(X_train.to_frame());\n",
    "    X_train = X_train.to_frame();\n",
    "    #print(X_train.head(3));\n",
    "    new_col_name = col_1_name + \"_\" + col_2_name + \"_Proba\"\n",
    "    X_train[col_2_name] = Y_train;\n",
    "    X_train[new_col_name] = label[:, 1];\n",
    "    \n",
    "    #fig = plt.figure();\n",
    "    #fig = X_train.groupby([new_col_name])[col_2_name].mean().plot();\n",
    "    \n",
    "    #X_train.groupby([new_col_name])[col_2_name].count().plot.bar();\n",
    "    \n",
    "    #interval = pd.concat( [X_train.groupby([new_col_name])[col_1_name].min(), X_train.groupby([new_col_name])[col_1_name].max()], axis=1)\n",
    "\n",
    "    with open(\"tree_model.txt\", \"w\") as f:\n",
    "        f = sklearn.tree.export_graphviz(tree_model, out_file=f);\n",
    "    dotfile = StringIO()\n",
    "    sklearn.tree.export_graphviz(tree_model, out_file=dotfile)\n",
    "    (graph, ) = pydot.graph_from_dot_data(dotfile.getvalue());\n",
    "    graph.write_png(\"tree_model.png\");\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] \"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-182-66841ca51df6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_discretisation_by_decision_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_dummies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TotalCharges'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Churn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-181-f5c4460fb29e>\u001b[0m in \u001b[0;36mdata_discretisation_by_decision_tree\u001b[1;34m(df, col_1_name, col_2_name, Test_size, Max_depth)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdotfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdotfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tree_model.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(path, f, prog, encoding)\u001b[0m\n\u001b[0;32m   1732\u001b[0m                 self.write(\n\u001b[0;32m   1733\u001b[0m                     \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1734\u001b[1;33m                     encoding=encoding)\n\u001b[0m\u001b[0;32m   1735\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'write_{fmt}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1815\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1920\u001b[0m                 args[1] = '\"{prog}\" not found in path.'.format(\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path."
     ]
    }
   ],
   "source": [
    "data_discretisation_by_decision_tree(df_dummies, 'TotalCharges', 'Churn', Max_depth = 2, Test_size = 0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Create X, Y matrix for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummies.values;\n",
    "Y = label.values;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Outlier detection by DBSCAN for all rows with one method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection_by_DBSCAN(df, Eps, Metric, Min_samples, N_jobs):\n",
    "    print(\"Condition: Data must be normalized by max-min method\")\n",
    "    outlier_detection = DBSCAN(eps=Eps, metric=Metric, min_samples = Min_samples, n_jobs = N_jobs);\n",
    "    df['outlier'] = outlier_detection.fit_predict(df);\n",
    "    outlier_indx = df[df.outlier == 0].index.values;\n",
    "    if (len(outlier_indx)>0):\n",
    "        df.iloc[outlier_indx,:]=np.nan;\n",
    "    df.drop(\"outlier\", axis=1, inplace=True);\n",
    "    removing_missing_values(telecom_cust);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7032, 46)\n",
      "Condition: Data must be normalized by max-min method\n",
      "(7032, 46)\n"
     ]
    }
   ],
   "source": [
    "print(df_dummies_dbscan.shape)\n",
    "outlier_detection_by_DBSCAN(df = df_dummies_dbscan, Eps = 2, Metric='euclidean', Min_samples = 5, N_jobs=-1);\n",
    "print(df_dummies_dbscan.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Outlier detection by Isolation Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection_by_IsolationRandomForest(X, Y, Max_samples=10, \n",
    "                                               Random_state = np.random.RandomState(42), \n",
    "                                               Contamination = 'auto', \n",
    "                                               Behaviour = 'new'):\n",
    "    clf = IsolationForest(max_samples=Max_samples, \n",
    "                          random_state=Random_state, \n",
    "                          contamination = Contamination, \n",
    "                          behaviour = Behaviour);\n",
    "    clf.fit(X, Y);\n",
    "    outliers = np.where(clf.predict(X) != -1);\n",
    "    X = X[outliers]\n",
    "    Y = Y[outliers]\n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detection_by_IsolationRandomForest(X,Y);\n",
    "print(X.shape);\n",
    "print(Y.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Divide data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing data set into training set, validation set, test set. Total = 7032\n",
    "- training set = 60%\n",
    "- val set = 20%\n",
    "- test set = 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2);\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape = (4218 , 45), Y train shape = (4218)\n",
      "X valid shape = (1407 , 45), Y valid shape = (1407)\n",
      "X test  shape = (1407 , 45), Y test  shape = (1407)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train shape = (%d , %d)\"%X_train.shape + \", Y train shape = (%d)\"%Y_train.shape);\n",
    "print(\"X valid shape = (%d , %d)\"%X_val.shape + \", Y valid shape = (%d)\"%Y_val.shape);\n",
    "print(\"X test  shape = (%d , %d)\"%X_test.shape + \", Y test  shape = (%d)\"%Y_test.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(X_train, open(\"X_train\", \"wb\"));\n",
    "pk.dump(Y_train, open(\"Y_train\", \"wb\"));\n",
    "pk.dump(X_val, open(\"X_val\", \"wb\"));\n",
    "pk.dump(Y_val, open(\"Y_val\", \"wb\"));\n",
    "pk.dump(X_test, open(\"X_test\", \"wb\"));\n",
    "pk.dump(Y_test, open(\"Y_test\", \"wb\"));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
