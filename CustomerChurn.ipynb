{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import pickle as pk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_cust = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_cust.TotalCharges = pd.to_numeric(telecom_cust.TotalCharges, errors='coerce')\n",
    "telecom_cust.MonthlyCharges = pd.to_numeric(telecom_cust.MonthlyCharges, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Removing the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_missing_values(telecom_cust):\n",
    "    telecom_cust.dropna(inplace = True);\n",
    "    telecom_cust.reset_index(drop=True, inplace = True);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n",
      "(7032, 21)\n"
     ]
    }
   ],
   "source": [
    "print(telecom_cust.shape);\n",
    "removing_missing_values(telecom_cust);\n",
    "print(telecom_cust.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_cust.to_csv(\"WA_Fn-UseC_-Telco-Customer-Churn-standard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Removing the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_duplicates(telecom_cust):\n",
    "    telecom_cust = pd.DataFrame.drop_duplicates(telecom_cust);\n",
    "    telecom_cust.reset_index(drop=True, inplace = True);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n"
     ]
    }
   ],
   "source": [
    "removing_duplicates(telecom_cust);\n",
    "print(telecom_cust.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Using mean-method in handling the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the missing values by mean-method.\n",
    "def set_missing_values_by_MEAN_METHOD(telecom_cust):\n",
    "    list_name_of_attributes = telecom_cust.columns;\n",
    "    for i in list_name_of_attributes:\n",
    "        #print(telecom_cust[i].value_counts().index);\n",
    "        if(telecom_cust[i].isnull().sum()>0 and telecom_cust[i].dtypes != 'object'):\n",
    "            telecom_cust[i].fillna(telecom_cust[i].mean(), inplace=True);\n",
    "        else:\n",
    "            if (telecom_cust[i].isnull().sum()>0 and telecom_cust[i].dtypes == 'object'):\n",
    "                #print(telecom_cust[i].value_counts().index);\n",
    "                telecom_cust[i].fillna(telecom_cust[i].value_counts().index.sort_values()[0], inplace=True);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_missing_values_by_MEAN_METHOD(telecom_cust);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Using mode-method in handling the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the missing values by mode-method.\n",
    "def set_missing_values_by_MODE_METHOD(telecom_cust):\n",
    "    list_name_of_attributes = telecom_cust.columns;\n",
    "    for i in list_name_of_attributes:\n",
    "        if(telecom_cust[i].isnull().sum()>0 and telecom_cust[i].dtypes != 'object'):\n",
    "            telecom_cust[i].fillna(telecom_cust[i].mode()[0], inplace=True);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_missing_values_by_MODE_METHOD(telecom_cust);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Using median-method in handling the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the missing values by median-method.\n",
    "def set_missing_values_by_MEDIAN_METHOD(telecom_cust):\n",
    "    list_name_of_attributes = telecom_cust.columns;\n",
    "    for i in list_name_of_attributes:\n",
    "        if(telecom_cust[i].isnull().sum()>0):\n",
    "            telecom_cust[i].fillna(telecom_cust[i].median(), inplace=True);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_missing_values_by_MEDIAN_METHOD(telecom_cust);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Normalizing data by max-min method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max-min method\n",
    "def normalization_data_max_min(telecom_cust):\n",
    "    for i in telecom_cust.columns:\n",
    "        if telecom_cust[i].dtypes != 'object':\n",
    "            max_value = telecom_cust[i].max();\n",
    "            min_value = telecom_cust[i].min();\n",
    "            telecom_cust[i] = (telecom_cust[i] - min_value)/(max_value - min_value);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_data_max_min(telecom_cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Normalizing data by z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-score method\n",
    "def normalization_data_z_score(telecom_cust):\n",
    "    for i in telecom_cust.columns:\n",
    "        if telecom_cust[i].dtypes != 'object':\n",
    "            meanX = telecom_cust[i].mean();\n",
    "            sd = telecom_cust[i].std();\n",
    "            telecom_cust[i] = (telecom_cust[i]-meanX)/sd;\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_data_z_score(telecom_cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Outlier detection by zscores for all rows with one method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(telecom_cust[\"TotalCharges\"]);\n",
    "def outlier_detection_by_zscores(telecom_cust, start, end):\n",
    "    print(\"Condition: Data frame must be normalized by z-scores before\");\n",
    "    for i in telecom_cust.columns:\n",
    "        if telecom_cust[i].dtypes != 'object':\n",
    "            telecom_cust[\"outlier\"] = telecom_cust[i].apply(lambda x: x <=start or x >= end);\n",
    "            outlier_indx = telecom_cust[telecom_cust.outlier==True].index.values;\n",
    "            if (len(outlier_indx)>0):\n",
    "                telecom_cust.iloc[outlier_indx,:]=np.nan;\n",
    "            telecom_cust.drop(\"outlier\", axis=1, inplace=True);\n",
    "    removing_missing_values(telecom_cust);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detection_by_zscores(telecom_cust,-2.5, 2.5)\n",
    "print(telecom_cust.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Remove a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove customer IDs from the data set\n",
    "df2 = telecom_cust.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Converting the string to int in the classed var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertin the predictor variable in a binary numeric variable\n",
    "df2['Churn'].replace(to_replace='Yes', value=1, inplace=True)\n",
    "df2['Churn'].replace(to_replace='No',  value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Convert all off categorical variables into dummy var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's convert all the categorical variables into dummy variables\n",
    "df_dummies = pd.get_dummies(df2)\n",
    "df_dummies_dbscan = pd.get_dummies(df2)\n",
    "label = df_dummies['Churn'].copy();\n",
    "df_dummies.drop(\"Churn\", axis=1, inplace = True);\n",
    "#df_dummies['Churn']=label;\n",
    "df_dummies.to_csv(\"CustomerChurn.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummies.values;\n",
    "Y = label.values;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Outlier detection by DBSCAN for all rows with one method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection_by_DBSCAN(df, Eps, Metric, Min_samples, N_jobs):\n",
    "    print(\"Condition: Data must be normalized by max-min method\")\n",
    "    outlier_detection = DBSCAN(eps=Eps, metric=Metric, min_samples = Min_samples, n_jobs = N_jobs);\n",
    "    df['outlier'] = outlier_detection.fit_predict(df);\n",
    "    outlier_indx = df[df.outlier == 0].index.values;\n",
    "    if (len(outlier_indx)>0):\n",
    "        df.iloc[outlier_indx,:]=np.nan;\n",
    "    df.drop(\"outlier\", axis=1, inplace=True);\n",
    "    removing_missing_values(telecom_cust);\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7032, 46)\n",
      "Condition: Data must be normalized by max-min method\n",
      "(7032, 46)\n"
     ]
    }
   ],
   "source": [
    "print(df_dummies_dbscan.shape)\n",
    "outlier_detection_by_DBSCAN(df = df_dummies_dbscan, Eps = 2, Metric='euclidean', Min_samples = 5, N_jobs=-1);\n",
    "print(df_dummies_dbscan.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Outlier detection by Isolation Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection_by_IsolationRandomForest(X, Y, Max_samples=10, \n",
    "                                               Random_state = np.random.RandomState(42), \n",
    "                                               Contamination = 'auto', \n",
    "                                               Behaviour = 'new'):\n",
    "    clf = IsolationForest(max_samples=Max_samples, \n",
    "                          random_state=Random_state, \n",
    "                          contamination = Contamination, \n",
    "                          behaviour = Behaviour);\n",
    "    clf.fit(X, Y);\n",
    "    outliers = np.where(clf.predict(X) != -1);\n",
    "    X = X[outliers]\n",
    "    Y = Y[outliers]\n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detection_by_IsolationRandomForest(X,Y);\n",
    "print(X.shape);\n",
    "print(Y.shape);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Divide data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing data set into training set, validation set, test set. Total = 7032\n",
    "- training set = 60%\n",
    "- val set = 20%\n",
    "- test set = 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2);\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape = (4218 , 45), Y train shape = (4218)\n",
      "X valid shape = (1407 , 45), Y valid shape = (1407)\n",
      "X test  shape = (1407 , 45), Y test  shape = (1407)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train shape = (%d , %d)\"%X_train.shape + \", Y train shape = (%d)\"%Y_train.shape);\n",
    "print(\"X valid shape = (%d , %d)\"%X_val.shape + \", Y valid shape = (%d)\"%Y_val.shape);\n",
    "print(\"X test  shape = (%d , %d)\"%X_test.shape + \", Y test  shape = (%d)\"%Y_test.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.dump(X_train, open(\"X_train\", \"wb\"));\n",
    "pk.dump(Y_train, open(\"Y_train\", \"wb\"));\n",
    "pk.dump(X_val, open(\"X_val\", \"wb\"));\n",
    "pk.dump(Y_val, open(\"Y_val\", \"wb\"));\n",
    "pk.dump(X_test, open(\"X_test\", \"wb\"));\n",
    "pk.dump(Y_test, open(\"Y_test\", \"wb\"));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
